{"cells":[{"cell_type":"markdown","metadata":{"id":"ezUEDOHilsMI"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FTNS1XQBRYMV"},"outputs":[],"source":["!pip install spacy &> /dev/null\n","!python -m spacy download en &> /dev/null\n","!pip install tmtoolkit &> /dev/null"]},{"cell_type":"markdown","metadata":{"id":"PROtU1pc52tV"},"source":["Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eg-tUpSq51ir"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","from sklearn.datasets import fetch_20newsgroups\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n","from sklearn import metrics\n","import pandas as pd\n","import spacy\n","import numpy as np\n","\n","import re\n","from pprint import pprint\n","from tqdm import tqdm\n","from IPython.core.display import HTML"]},{"cell_type":"markdown","metadata":{"id":"P-Ni1mD73EMr"},"source":["Settings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q_U_ikyF3FZS"},"outputs":[],"source":["use_sub_categories = True\n","categories = ['alt.atheism', 'sci.space', 'soc.religion.christian', 'talk.politics.guns']\n","RANDOM_STATE = 42"]},{"cell_type":"markdown","metadata":{"id":"zB-AWQZJIcpA"},"source":["Load dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13203,"status":"ok","timestamp":1628769695726,"user":{"displayName":"Marko Radovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghx1XW2yAOndMY6VpQCortiRa_k4FwEoWv98wQ9=s64","userId":"05554837114221040480"},"user_tz":-120},"id":"VD0HAy7JF74w","outputId":"9eedde54-9ad1-45f0-b2b6-7a0afd2c6873"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading 20news dataset. This may take a few minutes.\n","Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"]}],"source":["newsgroups_train_cleaned = fetch_20newsgroups(subset='train', \n","                                              remove=('headers', 'footers', 'quotes'), \n","                                              categories = categories if use_sub_categories else None,\n","                                              shuffle=True, \n","                                              random_state=RANDOM_STATE)\n","\n","X = newsgroups_train_cleaned.data\n","y = newsgroups_train_cleaned.target\n","target_names = newsgroups_train_cleaned.target_names"]},{"cell_type":"markdown","metadata":{"id":"14yIAFP0J1o0"},"source":["## Prepare data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"beIQU8RNzH6y"},"outputs":[],"source":["# Initialize spacy 'en' model, keeping only tagger component needed for lemmatization\n","nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L6LrfFY5VRn6"},"outputs":[],"source":["def preprocess(text):\n","    text = text.lower()\n","    text = text.strip()\n","    text = re.sub('\\d', '', text)  # remove numbers \n","    text = ' '.join(text.split())  # replace whitespace with single space\n","\n","    doc = nlp(text)\n","    tokens = [token.lemma_ for token in doc if not token.is_stop]\n","    tokens = [token for token in tokens if len(token) > 1]\n","\n","    return ' '.join(tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30629,"status":"ok","timestamp":1628769753521,"user":{"displayName":"Marko Radovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghx1XW2yAOndMY6VpQCortiRa_k4FwEoWv98wQ9=s64","userId":"05554837114221040480"},"user_tz":-120},"id":"OLwI9oJQkhh4","outputId":"1c9ffcdc-76c6-4f5a-df89-401696cebbc9"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2218/2218 [00:30<00:00, 73.32it/s]\n"]}],"source":["X_clean = [preprocess(doc) for doc in tqdm(X)]"]},{"cell_type":"markdown","metadata":{"id":"Imtca99BjLzs"},"source":["Let's fit vectorizer with preprocessed data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jkkc4J-BjKjh"},"outputs":[],"source":["vectorizer = CountVectorizer(max_df=0.95, \n","                             min_df=2,\n","                             max_features=1000)\n","\n","tf = vectorizer.fit_transform(X_clean)\n","vocabulary = vectorizer.get_feature_names()"]},{"cell_type":"markdown","metadata":{"id":"IE9HBjjsMh5e"},"source":["## Scikit-learn topic modeling with LDA"]},{"cell_type":"markdown","metadata":{"id":"F6Nfrnp0-Zmi"},"source":["### Find best number of topics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xGTSs_jMqxQ2"},"outputs":[],"source":["def get_lda_model(n_topics=10):  # this is default value\n","    return LatentDirichletAllocation(n_components=n_topics,\n","                                     max_iter=5,\n","                                     learning_method='online',\n","                                     learning_offset=50.,\n","                                     random_state=RANDOM_STATE)"]},{"cell_type":"markdown","metadata":{"id":"GEc1W816HqNC"},"source":["Show top words per topic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B4dpdkcpLHBF"},"outputs":[],"source":["def get_top_words_per_topics(model, vocabulary, n_top_words=10):\n","    top_words = [] \n","    for topic in model.components_:  # word distribution per topic \n","        top_words.append([vocabulary[i]\n","                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n","    \n","    df = pd.DataFrame(top_words)\n","    df.index = [\"Topic \" + str(i) for i in range(len(top_words))]\n","    df.columns = [\"Word \" + str(i) for i in range(len(top_words[0]))]\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":4393,"status":"ok","timestamp":1628769758323,"user":{"displayName":"Marko Radovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghx1XW2yAOndMY6VpQCortiRa_k4FwEoWv98wQ9=s64","userId":"05554837114221040480"},"user_tz":-120},"id":"edPwT9mowrDb","outputId":"70b57da6-e744-47b2-b678-986b5b16fd8d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Word 0</th>\n","      <th>Word 1</th>\n","      <th>Word 2</th>\n","      <th>Word 3</th>\n","      <th>Word 4</th>\n","      <th>Word 5</th>\n","      <th>Word 6</th>\n","      <th>Word 7</th>\n","      <th>Word 8</th>\n","      <th>Word 9</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Topic 0</th>\n","      <td>gun</td>\n","      <td>people</td>\n","      <td>right</td>\n","      <td>law</td>\n","      <td>weapon</td>\n","      <td>firearm</td>\n","      <td>state</td>\n","      <td>file</td>\n","      <td>government</td>\n","      <td>think</td>\n","    </tr>\n","    <tr>\n","      <th>Topic 1</th>\n","      <td>god</td>\n","      <td>people</td>\n","      <td>know</td>\n","      <td>think</td>\n","      <td>believe</td>\n","      <td>say</td>\n","      <td>jesus</td>\n","      <td>thing</td>\n","      <td>time</td>\n","      <td>come</td>\n","    </tr>\n","    <tr>\n","      <th>Topic 2</th>\n","      <td>space</td>\n","      <td>nasa</td>\n","      <td>launch</td>\n","      <td>system</td>\n","      <td>orbit</td>\n","      <td>satellite</td>\n","      <td>year</td>\n","      <td>earth</td>\n","      <td>program</td>\n","      <td>mission</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Word 0  Word 1  Word 2  Word 3  ... Word 6 Word 7      Word 8   Word 9\n","Topic 0    gun  people   right     law  ...  state   file  government    think\n","Topic 1    god  people    know   think  ...  jesus  thing        time     come\n","Topic 2  space    nasa  launch  system  ...   year  earth     program  mission\n","\n","[3 rows x 10 columns]"]},"execution_count":12,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["model = get_lda_model(n_topics=3)\n","model.fit(tf)\n","get_top_words_per_topics(model, vocabulary)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nJ7rUmXVPf2u"},"outputs":[],"source":["import pickle\n","\n","# now you can save it to a file\n","with open('model.pkl', 'wb') as f:\n","    pickle.dump(model, f)\n","\n","# and later you can load it\n","with open('model.pkl', 'rb') as f:\n","    model = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NqrTDp94UC9o"},"outputs":[],"source":["# now you can save it to a file\n","with open('vocabulary.pkl', 'wb') as f:\n","    pickle.dump(vocabulary, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TXqpm5i6dDwj"},"outputs":[],"source":["# now you can save it to a file\n","with open('vectorizer.pkl', 'wb') as f:\n","    pickle.dump(vectorizer, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":289,"status":"ok","timestamp":1628775078582,"user":{"displayName":"Marko Radovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghx1XW2yAOndMY6VpQCortiRa_k4FwEoWv98wQ9=s64","userId":"05554837114221040480"},"user_tz":-120},"id":"CQ9V46OfQKld","outputId":"86b7046d-816e-4507-bd71-f8676ad08af6"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.06473069335308923, 0.5484120850034417, 0.3868572216434691]\n","Topic #0: 0.06473069335308923\n","Topic #1: 0.5484120850034417\n","Topic #2: 0.3868572216434691\n"]}],"source":["text = 'I support theory that some higher intelligence created this world'\n","text = preprocess(text)\n","term_freq = vectorizer.transform([text])\n","\n","output = model.transform(term_freq)\n","\n","for topic_idx, _ in enumerate(model.components_):\n","    print(f\"Topic #{topic_idx}: {output[0][topic_idx]}\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP/v7WsfDWy8DWIis5zy7q4","collapsed_sections":["14yIAFP0J1o0","jGMPRjj5-eDb"],"name":"4. Prepare for Deployment","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
